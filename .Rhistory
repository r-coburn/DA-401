library(dplyr)
read_data <- function(data) {
data <- read.table(data, header = FALSE, sep = " ", dec = ".")
muons <- as.data.frame(data$V1)
names(muons) <- "Decay_Time"
decay_time <- muons %>%
filter(Decay_Time < 40000) %>%
mutate(decay_time = Decay_Time/10^3) %>%
dplyr::select(decay_time)
}
subtract_background_1 <- function(data) {
first_mean <- mean(data$decay_time)
first_background <- round((max(data$decay_time) + first_mean*5)/2, digits = 0)
bin <- data.frame(decay_time = filter(data, 0 < decay_time & decay_time <= 1)[-sample(1:nrow(filter(data, 0 < decay_time & decay_time <= 1)), first_background), ])
for(i in 2:20) {
df <- data.frame(decay_time = filter(data, i-1 < decay_time & decay_time <= i))
if(nrow(df) > first_background) {
bin <- rbind(bin, data.frame(decay_time = df[-sample(1:nrow(df), first_background), ]))
}
}
return(bin)
}
subtract_background_all <- function(data) {
d <- subtract_background_1(data)
for(i in 2:3) {
d <- subtract_background_1(d)
}
return(d)
}
fit_data <- function(data) {
d <- subtract_background_all(read_data(data))
decay_rate = 1/mean(d$decay_time, na.rm = T)
decay_time_mean <- mean(d$decay_time)
y = seq(0.25, trunc(max(d$decay_time)), by = 0.5)
hist_info <- hist(d$decay_time, freq = F, breaks = 20, plot = F)
density <- hist_info$density
error_std <- sqrt(hist_info$counts)/nrow(d)
hist(d$decay_time, freq = FALSE, main = "Histogram of Muon Decay Time", xlab = "Decay Time (microseconds)", breaks = 20)
curve(dexp(x, rate = decay_rate), from = 0, col = "red", add = TRUE)
arrows(y, density+error_std, y, density-error_std, length=0.05, angle=90, code=3)
return(paste(paste(paste(paste(paste("The 95% confidence interval for the mean muon decay time using the maximum likelihood estimator for the fitted exponential distribution is (",toString(c(round(decay_time_mean - 1.96*sqrt((decay_time_mean)^2/nrow(d)), 2), round(decay_time_mean + 1.96*sqrt((decay_time_mean)^2/nrow(d)), 2)))), ") microseconds")), "with a mean of ", toString(round(decay_time_mean, 2)), " microseconds")))
}
linearize_analysis.unweighted <- function(data) {
d <- subtract_background_all(read_data(data))
hist_info <- hist(d$decay_time, breaks = 20, freq = F, plot = F)
log.mod <- lm(log(hist_info$counts) ~ hist_info$mids)
decay_rate <- -1*summary(log.mod)$coefficients[2]
se.mod <- summary(log.mod)$coefficients[4]
log_counts <- log(hist_info$counts)
mids <- hist_info$mids
se <- log(sqrt(hist_info$counts))
ymin <- min(log_counts)-min(se)-1
ymax <- max(log_counts)+max(se)+1
confidence <- confint(log.mod)
plot(hist_info$mids, log(hist_info$counts), xlab = "Muon Decay Time (microseconds)", ylab = "Natural Logarithm of Counts", ylim = c(ymin, ymax), main = "Linearized Muon Decay Time Counts using Least Squares")
abline(log.mod, col = "red")
arrows(mids, log_counts+se, mids, log_counts-se, length=0.05, angle=90, code=3)
return(paste(paste(paste(paste(paste("The 95% confidence interval for the mean muon decay time using unweighed least squares is (", toString(c(round(-1/confidence[2], 2), round(-1/confidence[4], 2)))), ") microseconds", "with a mean of ", toString(round(1/decay_rate, 2)), " microseconds")))))
}
linearize_analysis.weighted <- function(data) {
d <- subtract_background_all(read_data(data))
hist_info <- hist(d$decay_time, breaks = 20, freq = F, plot = F)
log.mod <- lm(log(hist_info$counts) ~ hist_info$mids)
wt <- 1 / lm(abs(log.mod$residuals) ~ log.mod$fitted.values)$fitted.values^2
wlm <- lm(log(hist_info$counts) ~ hist_info$mids, weights = wt)
decay_rate.weighted <- -1*summary(wlm)$coefficients[2]
se.mod.weighted <- summary(wlm)$coefficients[4]
log_counts <- log(hist_info$counts)
mids <- hist_info$mids
se <- log(sqrt(hist_info$counts))
ymin <- min(log_counts)-min(se)-1
ymax <- max(log_counts)+max(se)+1
confidence <- confint(wlm)
plot(hist_info$mids, log(hist_info$counts), xlab = "Muon Decay Time (microseconds)", ylab = "Natural Logarithm of Counts", ylim = c(ymin, ymax), main = "Linearized Muon Decay Time Counts using Weighted Least Squares")
abline(wlm, col = "red")
arrows(mids, log_counts+se, mids, log_counts-se, length=0.05, angle=90, code=3)
return(paste(paste(paste(paste(paste("The 95% confidence interval for the mean muon decay time using weighed least squares is (", toString(c(round(-1/confidence[2], 2), round(-1/confidence[4], 2)))), ") microseconds", "with a mean of ", toString(round(1/decay_rate.weighted, 2)), " microseconds")))))
}
nrow(subtract_background_all(read_data("Threshold 0.5 volts.data")))
sub_1 <- subtract_background_1(read_data("Threshold 0.5 volts.data"))
sub_1 <- subtract_background_1(read_data("Threshold 0.5 volts.data"))
sub_2 <- subtract_background_1(sub_1)
mean(sub_2, na.rm = T)
mean(sub_2, na.rm = F)
sub_2
mean(sub_2$decay_time, na.rm = F)
mean(sub_1$decay_time, na.rm = F)
knitr::opts_chunk$set(echo = TRUE)
c(rep(0,400),rep(1,399))
numerical.data.random$team <- c(rep(0,400),rep(1,399))
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
data <- read.csv("sampled_data.csv")
numerical.data <- na.omit(data[,8:33])
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
library(cutpointr)
library(ROCit)
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
summary(cp)
set.seed(11)
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
summary(cp) #accurary 0.60
set.seed(15)
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
summary(cp) #accurary 0.60, 0.57
cp$acc
random.model.accuracy <- c()
for(i in 1:30) {
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
random.model.accuracy[i] <- cp$acc
}
hist(random.model.accuracy)
set.seed(1)
random.model.accuracy <- c()
for(i in 1:50) {
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
random.model.accuracy[i] <- cp$acc
}
hist(random.model.accuracy)
pred_test <- predict(random.mod, numerical.data.random, type = "response")
pred_test
length(pred_test)
?predict
pred_test <- predict(random.mod, numerical.data.random, type = "class")
pred_test <- predict(random.mod, numerical.data.random, type = "terms")
length(pred_test)
pred_test <- predict(random.mod, numerical.data.random, type = "response")
length(pred_test)
glm.pred = rep(0,length(numerical_data.random))
glm.pred = rep(0,length(numerical.data.random))
glm.pred[pred_test>.5] <- 1
glm.pred
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
glm.pred = rep(0,length(numerical.data.random))
glm.pred[probs>.5] <- 1
glm.pred
is.na(probs)
glm.pred = rep(0,length(numerical.data.random))
glm.pred[as.numeric(probs)>.5] <- 1
glm.pred
probs
glm.pred <- c()
glm.pred <- ifelse(probs > 0.5, 1, 0)
glm.pred
sum(glm.pred+numerical.data.random$team)
glm.pred + numerical.data.random$team
sum(glm.pred+numerical.data.random$team==1)
(length(glm.pred)-sum(glm.pred+numerical.data.random$team==1))/length(glm.pred)
last.500 <- tail(numerical.data, 500)
numerical.data <- tail(numerical.data, 500)
set.seed(1)
random.model.accuracy <- c()
for(i in 1:50) {
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,400),rep(1,399))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
random.model.accuracy[i] <- cp$acc
}
data <- read.csv("sampled_data.csv")
numerical.data <- na.omit(data[,8:33])
numerical.data <- tail(numerical.data, 500)
set.seed(1)
random.model.accuracy <- c()
for(i in 1:50) {
numerical.data.random <- numerical.data[sample(nrow(numerical.data)),]
numerical.data.random$team <- c(rep(0,250),rep(1,250))
random.mod <- glm(factor(team)~., data = numerical.data.random, family = "binomial")
summary(random.mod)
numerical.data.random$probs = predict(random.mod, newdata=numerical.data.random, type="response")
probs <- numerical.data.random$probs
team <- as.factor(numerical.data.random$team)
cp <- cutpointr(str(data.frame(probs, team)), probs, team, method = maximize_metric, metric = accuracy, na.rm = T)
random.model.accuracy[i] <- cp$acc
}
hist(random.model.accuracy)
numerical.data <- na.omit(data[,8:33])
str(numerical.data)
data.norm <- scale(numerical.data)
corr_mat <- cor(data.norm)
library(cor)
numerical.data <- na.omit(data[,8:33])
str(numerical.data)
data.norm <- scale(numerical.data)
corr_mat <- cor(data.norm)
data.pca <- princomp(corr_mat)
summary(data.pca)
data.pca$loadings[,1:10]
data.pca
summary(data.pca)
data.pca$loadings[,1:10]
loadings <- data.pca$loadings[,1:10]
dim(loadings)
dim(numerical.data)
prin.coms <- numerical.data*loadings
prin.coms
prin.coms <- numerical.data*loadings
dim(prin.coms)
prin.coms <- numerical.data%*%loadings
prin.coms <- numerical.data*loadings
dim(numerical.data)
dim(loadings)
prin.coms
prin.coms <- numerical.data %*% loadings
prin.coms <- as.matrix(numerical.data) %*% as.matrix(loadings)
prin.coms
prin.coms <- data.frame(as.matrix(numerical.data) %*% as.matrix(loadings))
prin.coms
prin.coms$rock <- data$rock
prin.coms$rock <- na.omit(data)$rock
pca.mod <- glm(factor(rock)~., data = prin.coms, family = "binomial")
summary(pca.mod)
pca.mod <- glm(factor(rock)~., data = prin.coms, family = "binomial")
summary(pca.mod)
prin.coms$probs <- predict(pca.mod, newdata = prin.coms, type = "response")
probs <- prin.coms$probs
team <- as.factor(prin.coms$team)
probs <- prin.coms$probs
rock <- as.factor(prin.coms$rock)
cp <- cutpointr(str(data.frame(probs, rock)), probs, rock, method = maximize_metric, metric = accuracy, na.rm = T)
summary(cp)
bigger_data <- do.call(rbind, list(rock_sam, polish_sample, post_punk_sample, gospel_sample))
data <- read.csv("sampled_data.csv")
data
all.data <- data[,c(8:33,35)]
all.mod <- glm(factor(rock)~., data = all.data, family = "binomial")
summary(all.mod)
probs <- predict(all.mod, newdata = all.data, type = "response")
rock <- all.data$rock
cp <- cutpointr(str(data.frame(probs, rock)), probs, rock, method = maximize_metric, metric = accuracy, na.rm = T)
summary(cp)
setwd("~/Desktop/Denison/DA/DA 401/Project/Data")
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("sample.csv")
setwd("~/Desktop/Denison/DA/DA 401/Project")
data <- read.csv("sample.csv")
setwd("~/Desktop/Denison/DA/DA 401/Project")
data <- read.csv("sample.csv")
View(data)
data <- tail(data, 700)
data <- rbind(head(data, 500), tail(data, 100))
library(glmnet)
library(glmnet)
library(cutpointr)
features <- data[c(5,8:33),]
View(features)
features <- data[,c(5,8:33)]
View(features)
cv.mod <- cv.glmnet(x = as.matrix(features), y = rock, family = "binomial", type.measure = "class")
cv.mod <- cv.glmnet(x = as.matrix(features), y = rock, family = "binomial", type.measure = "class")
features <- data[,c(5,8:33)]
rock <- data$rock
cv.mod <- cv.glmnet(x = as.matrix(features), y = rock, family = "binomial", type.measure = "class")
lambda <- cv.mod$lambda.min
mod <- glmnet(features, rock, family = "binomial", lambda = lambda)
mod.probs <- predict(mod, newx = as.matrix(features), type = "response")
data$mod.probs <- mod.probs[,1]
rock.class <- ifelse(data$rock == 1, "rock", "not rock")
logistic.probs <- data$mod.probs
mod.cp <- cutpointr(data.frame(rock.class, logistic.probs), x=logistic.probs, class = rock.class, method = maximize_metric, metric = accuracy)
summary(mod.cp) # accuracy = 67.12%
library(cutpointr)
library(car)
library(glmnet)
library(class)
library(caret)
set.seed(1)
n = nrow(data)
index <- sample(1:n, size = n*0.7)
training <- data[index,]
test <- data[-index,]
train.features <- data.frame(training[,c(5,8:33)])
train.rock <- training$rock
# predictor in test set, will be used for prediction
test.features <-  data.frame(test[,c(5,8:33)])
test.rock <- as.factor(test$rock)
# gut check
set.seed(1)
balanced.data.random <- rbind(head(data, 400), tail(data, 100))
table((balanced.data.random$genre))
random.features <- balanced.data.random[,c(5,8:33)]
random.model.accuracy <- c()
for(i in 1:50) {
data.random <- random.features[sample(nrow(random.features)),]
team <- c(rep(0,250),rep(1,250))
cv.mod.random <- cv.glmnet(x = as.matrix(data.random), y = team, family = "binomial", type.measure = "class")
lambda <- cv.mod.random$lambda.min
mod <- glmnet(as.matrix(data.random), team, family = "binomial", lambda = lambda)
random.probs <- predict(mod, newx = as.matrix(data.random), type = "response")
team.class <- ifelse(team == 1, "team 1", "team 2")
mod.cp <- cutpointr(data.frame(team.class, random.probs), x=random.probs, class = team.class, method = maximize_metric, metric = accuracy)
random.model.accuracy[i] <- mod.cp$acc
}
hist(random.model.accuracy); mean(random.model.accuracy) # accuracy = 58.92%
# first logistic regression model (L2 regularized with all variables)
cv.mod <- cv.glmnet(x = as.matrix(features), y = rock, family = "binomial", type.measure = "class")
lambda <- cv.mod$lambda.min
mod <- glmnet(features, rock, family = "binomial", lambda = lambda)
mod.probs <- predict(mod, newx = as.matrix(features), type = "response")
data$mod.probs <- mod.probs[,1]
rock.class <- ifelse(data$rock == 1, "rock", "not rock")
logistic.probs <- data$mod.probs
mod.cp <- cutpointr(data.frame(rock.class, logistic.probs), x=logistic.probs, class = rock.class, method = maximize_metric, metric = accuracy)
summary(mod.cp) # accuracy = 67.12%
plot(x = data$year, y = data$mod.probs, col = factor(data$genre), main = "Predicted Probability of Rock Music by Release Year", xlab = "Year", ylab = "Precicted Probabilty of Rock")
abline(h = mod.cp$optimal_cutpoint, lty = 2, col = "orange", lwd = 3)
legend("bottomleft", legend=unique(data$genre),
col=factor(unique(data$genre)), pch=1, cex=0.8,
title="Genres", text.font=4)
# second logistic regression model (L2 reguularized with PCA)
features.norm <- scale(features)
corr.mat <- cor(features.norm)
features.pca <- princomp(corr.mat)
summary(features.pca) # top 20 principal components make up over 99% of variance, top 7 over 80%, and first two almost 50%
loadings.20 <- features.pca$loadings[,1:20]
loadings.7 <- features.pca$loadings[,1:7]
loadings.2 <- features.pca$loadings[,1:2]
prin.coms <- data.frame(as.matrix(features) %*% as.matrix(features.pca$loadings))
cv.mod.pca <- cv.glmnet(x = as.matrix(prin.coms), y = rock, family = "binomial", type.measure = "class")
lambda.pca <- cv.mod.pca$lambda.min
mod.pca <- glmnet(prin.coms, rock, family = "binomial", lambda = lambda.pca)
mod.probs.pca <- predict(mod.pca, newx = as.matrix(prin.coms), type = "response")
data$mod.probs.pca <- mod.probs.pca[,1]
rock.class <- ifelse(data$rock == 1, "rock", "not rock")
logistic.probs.pca <- data$mod.probs.pca
mod.cp.pca <- cutpointr(data.frame(rock.class, logistic.probs.pca), x=logistic.probs.pca, class = rock.class, method = maximize_metric, metric = accuracy)
summary(mod.cp.pca) # accuracy = 65%
plot(x = prin.coms$Comp.1, y = prin.coms$Comp.2, col = factor(data$genre), main = "Spotify Music by its first two principal components", xlab = "Pincipal Component 1", ylab = "Principal Componenet 2")
legend("bottomleft", legend=unique(data$genre),
col=factor(unique(data$genre)), pch=1, cex=0.8,
title="Genres", text.font=4)
# first KNN
accuracy <- c()
for(i in 1:100){
predicted <- knn(train = train.features, test = test.features, cl = train.rock, k = i)
ConMat <- table(test.rock, predicted)
TN <- ConMat[1,1]
FP <- ConMat[1,2]
FN <- ConMat[2,1]
TP <- ConMat[2,2]
accuracy[i] <- (TP + TN)/sum(ConMat)
}
plot(accuracy)
which.max(accuracy) # optimal K = 6
max(accuracy) #classification accuracy of 60.0%
# second KNN (with PCA)
train.features.norm <- scale(train.features)
train.corr.mat <- cor(train.features.norm)
train.features.pca <- princomp(train.corr.mat)
summary(train.features.pca) # top 20 principal components make up over 99% of variance and first two almost 50%
train.prin.coms <- data.frame(as.matrix(train.features) %*% as.matrix(train.features.pca$loadings))
test.features.norm <- scale(test.features)
test.corr.mat <- cor(test.features.norm)
test.features.pca <- princomp(test.corr.mat)
summary(test.features.pca)
test.prin.coms <- data.frame(as.matrix(test.features) %*% as.matrix(test.features.pca$loadings))
# all principal components
accuracy <- c()
for(i in 1:100){
predicted <- knn(train = train.prin.coms, test = test.prin.coms, cl = train.rock, k = i)
ConMat <- table(test.rock, predicted)
TN <- ConMat[1,1]
FP <- ConMat[1,2]
FN <- ConMat[2,1]
TP <- ConMat[2,2]
accuracy[i] <- (TP + TN)/sum(ConMat)
}
plot(accuracy)
which.max(accuracy) # optimal K = 70
max(accuracy) # classification accuracy of 58.33%
# testing for acoustic coherence
rm(accuracy)
early <- data[data$year<=median(data$year),] # 407 observations
late <- data[data$year>median(data$year),] # 393 observations
early.features <- early[,c(5,8:33)]
early.rock <- early$rock
late.features <- late[,c(5,8:33)]
late.rock <- late$rock
# logistic regression with all variables (early)
cv.mod.early <- cv.glmnet(x = as.matrix(early.features), y = early.rock, family = "binomial", type.measure = "class")
lambda <- cv.mod.early$lambda.min
mod.early <- glmnet(early.features, early.rock, family = "binomial", lambda = lambda)
mod.early.probs <- predict(mod.early, newx = as.matrix(early.features), type = "response")
early$mod.early.probs <- mod.early.probs[,1]
early.rock.class <- ifelse(early.rock == 1, "rock", "not rock")
logistic.probs <- early$mod.early.probs
mod.early.cp <- cutpointr(data.frame(early.rock.class, logistic.probs), x=logistic.probs, class = early.rock.class, method = maximize_metric, metric = accuracy)
summary(mod.early.cp) # accuracy = 68.55%
# logistic regression with all variables (late)
cv.mod.late <- cv.glmnet(x = as.matrix(late.features), y = late.rock, family = "binomial", type.measure = "class")
lambda <- cv.mod.late$lambda.min
mod.late <- glmnet(late.features, late.rock, family = "binomial", lambda = lambda)
mod.late.probs <- predict(mod.late, newx = as.matrix(late.features), type = "response")
late$mod.late.probs <- mod.late.probs[,1]
late.rock.class <- ifelse(late.rock == 1, "rock", "not rock")
logistic.probs <- late$mod.late.probs
mod.late.cp <- cutpointr(data.frame(late.rock.class, logistic.probs), x=logistic.probs, class = late.rock.class, method = maximize_metric, metric = accuracy)
summary(mod.late.cp) # accuracy = 70.48%
# logistic regression with principal components (early)
early.features.norm <- scale(early.features)
early.corr.mat <- cor(early.features.norm)
early.features.pca <- princomp(early.corr.mat)
summary(early.features.pca)
early.prin.coms <- data.frame(as.matrix(early.features) %*% as.matrix(early.features.pca$loadings))
early.cv.mod.pca <- cv.glmnet(x = as.matrix(early.prin.coms), y = early.rock, family = "binomial", type.measure = "class")
early.lambda.pca <- early.cv.mod.pca$lambda.min
early.mod.pca <- glmnet(early.prin.coms, early.rock, family = "binomial", lambda = early.lambda.pca)
early.mod.probs.pca <- predict(early.mod.pca, newx = as.matrix(early.prin.coms), type = "response")
early$early.mod.probs.pca <- early.mod.probs.pca[,1]
early.rock.class <- ifelse(early.rock == 1, "rock", "not rock")
early.logistic.probs.pca <- early$early.mod.probs.pca
early.mod.cp.pca <- cutpointr(data.frame(early.rock.class, early.logistic.probs.pca), x=early.logistic.probs.pca, class = early.rock.class, method = maximize_metric, metric = accuracy)
summary(early.mod.cp.pca) # accuracy = 67.57%
# logistic regression with principal components (late)
late.features.norm <- scale(late.features)
late.corr.mat <- cor(late.features.norm)
late.features.pca <- princomp(late.corr.mat)
summary(late.features.pca)
late.prin.coms <- data.frame(as.matrix(late.features) %*% as.matrix(late.features.pca$loadings))
late.cv.mod.pca <- cv.glmnet(x = as.matrix(late.prin.coms), y = late.rock, family = "binomial", type.measure = "class")
late.lambda.pca <- late.cv.mod.pca$lambda.min
late.mod.pca <- glmnet(late.prin.coms, late.rock, family = "binomial", lambda = late.lambda.pca)
late.mod.probs.pca <- predict(late.mod.pca, newx = as.matrix(late.prin.coms), type = "response")
late$late.mod.probs.pca <- late.mod.probs.pca[,1]
late.rock.class <- ifelse(late.rock == 1, "rock", "not rock")
late.logistic.probs.pca <- late$late.mod.probs.pca
late.mod.cp.pca <- cutpointr(data.frame(late.rock.class, late.logistic.probs.pca), x=late.logistic.probs.pca, class = late.rock.class, method = maximize_metric, metric = accuracy)
summary(late.mod.cp.pca) #67.68
# test for acoustic coherence (feature set)
accoustic.coherence.probs <- predict(early.mod.pca, newx = as.matrix(late.features), type = "response")
accoustic.coherence.cp <- cutpointr(data.frame(late.rock.class, accoustic.coherence.probs), x=accoustic.coherence.probs, class = late.rock.class, method = maximize_metric, metric = accuracy)
summary(accoustic.coherence.cp) # accuracy = 55.98%
# test for acoustic coherence (PCA)
accoustic.coherence.probs.pca <- predict(early.mod.pca, newx = as.matrix(late.prin.coms), type = "response")
accoustic.coherence.cp.pca <- cutpointr(data.frame(late.rock.class, accoustic.coherence.probs), x=accoustic.coherence.probs, class = late.rock.class, method = maximize_metric, metric = accuracy)
summary(accoustic.coherence.cp.pca) # accuracy = 53.69%
accuracy <- c()
for(i in 1:100){
predicted <- knn(train = train.features, test = test.features, cl = train.rock, k = i)
ConMat <- table(test.rock, predicted)
TN <- ConMat[1,1]
FP <- ConMat[1,2]
FN <- ConMat[2,1]
TP <- ConMat[2,2]
accuracy[i] <- (TP + TN)/sum(ConMat)
}
)
max(accuracy) #classification accuracy of 60.0%
# second KNN (with PCA)
train.features.norm <- scale(train.features)
train.corr.mat <- cor(train.features.norm)
train.features.pca <- princomp(train.corr.mat)
summary(train.features.pca) # top 20 principal components make up over 99% of variance and first two almost 50%
train.prin.coms <- data.frame(as.matrix(train.features) %*% as.matrix(train.features.pca$loadings))
test.features.norm <- scale(test.features)
test.corr.mat <- cor(test.features.norm)
test.features.pca <- princomp(test.corr.mat)
summary(test.features.pca)
test.prin.coms <- data.frame(as.matrix(test.features) %*% as.matrix(test.features.pca$loadings))
# all principal components
accuracy <- c()
for(i in 1:100){
predicted <- knn(train = train.prin.coms, test = test.prin.coms, cl = train.rock, k = i)
ConMat <- table(test.rock, predicted)
TN <- ConMat[1,1]
FP <- ConMat[1,2]
FN <- ConMat[2,1]
TP <- ConMat[2,2]
accuracy[i] <- (TP + TN)/sum(ConMat)
}
max(accuracy) # classification accuracy of 58.33%
knitr::opts_chunk$set(echo = TRUE)
hist(random.model.accuracy); mean(random.model.accuracy) # accuracy = 58.92%
