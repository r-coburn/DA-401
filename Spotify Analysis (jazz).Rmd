---
title: "Jazz Analysis"
author: "Riley Coburn"
date: "2023-04-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(cutpointr)
library(car)
library(glmnet)
library(class)
library(caret)
library(GGally)
```

```{r}
# read data
setwd("~/Desktop/Denison/DA/DA 401/Project/Data")
data <- read.csv("jazz_sample.csv")
data <- data[,-1]
dim(na.omit(data)) # 796 values, 36 features
data <- na.omit(data)
features <- data[,c(5,8:21,23:33)]
jazz <- data$jazz

set.seed(1)
n = nrow(data)
index <- sample(1:n, size = n*0.7)
training <- data[index,]
test <- data[-index,]

train.features <- data.frame(training[,c(5,8:33)]) 
train.jazz <- training$jazz

# predictor in test set, will be used for prediction
test.features <-  data.frame(test[,c(5,8:33)])
test.jazz <- as.factor(test$jazz)
```

```{r, warning = F}
# gut check

set.seed(1)
balanced.data.random <- rbind(head(data, 400), tail(data, 400)[sample(1:400,100),])
table((balanced.data.random$genre))
random.features <- balanced.data.random[,c(5,8:33)]
random.model.accuracy <- c()

for(i in 1:50) {
  n.random = nrow(random.features)
  index <- sample(1:n.random, size = n.random*0.7)
  random.training <- random.features[index, ]
  random.testing <- random.features[-index, ]

  data.random <- random.training[sample(nrow(random.training)),]
  team <- c(rep(0,175),rep(1,175))
  
  cv.mod.random <- cv.glmnet(x = as.matrix(data.random), y = team, family = "binomial", type.measure = "class")
  lambda <- cv.mod.random$lambda.min

  mod <- glmnet(as.matrix(data.random), team, family = "binomial", lambda = lambda)
  
  testing.random <- random.testing[sample(nrow(random.testing)),]
  test.team <- c(rep(0, 75), rep(1, 75))
  
  mod <- glmnet(as.matrix(testing.random), test.team, family = "binomial", lambda = lambda)
  
  random.probs <- predict(mod, newx = as.matrix(random.testing), type = "response")
  team.class <- ifelse(test.team == 1, "team 1", "team 2")
  mod.cp <- cutpointr(data.frame(team.class, random.probs), x=random.probs, class = team.class, method = maximize_metric, metric = accuracy)

  random.model.accuracy[i] <- mod.cp$acc
}

hist(random.model.accuracy, main = "Random Model Accuracy", xlab = "Random Model Accuracy")
mean(random.model.accuracy) # accuracy = 57.87%
```

```{r}
# first logistic regression model (L2 regularized with all variables)

cv.mod <- cv.glmnet(x = as.matrix(features), y = jazz, family = "binomial", type.measure = "class")
lambda <- cv.mod$lambda.min

mod <- glmnet(features, jazz, family = "binomial", lambda = lambda)
mod.probs <- predict(mod, newx = as.matrix(features), type = "response")
data$mod.probs <- mod.probs[,1]
jazz.class <- ifelse(data$jazz == 1, "jazz", "not jazz")
logistic.probs <- data$mod.probs
mod.cp <- cutpointr(data.frame(jazz.class, logistic.probs), x=logistic.probs, class = jazz.class, method = maximize_metric, metric = accuracy)
summary(mod.cp) # accuracy = 77.64%

plot(x = data$year, y = data$mod.probs, col = factor(data$genre), main = "Predicted Probability of jazz Music by Release Year", xlab = "Year", ylab = "Predicted Probabilty of jazz")
legend("bottomleft", legend=unique(data$genre),
       col=factor(unique(data$genre)), pch=1, cex=0.8,
       title="Genres", text.font=4)

plot(x = data$p8, y = data$mod.probs, col = factor(data$genre), main = "Predicted Probability of jazz Music by 8th Pitch Class", xlab = "Pitch Class 8", ylab = "Predicted Probabilty of jazz")
legend("bottomright", legend=unique(data$genre),
       col=factor(unique(data$genre)), pch=1, cex=0.8,
       title="Genres", text.font=4)

logit <- mod.probs/(1-mod.probs)
ggpairs(cbind(features, logit))
plot(glm(jazz~., data = data.frame(features, jazz), family = "binomial")
, which = 4, id.n = 5)
car::vif(glm(jazz~., data = data.frame(features, jazz), family = "binomial")
)
```

```{r}
# second logistic regression model (L2 reguularized with PCA)

features.norm <- scale(features)
corr.mat <- cor(features.norm)
features.pca <- princomp(corr.mat)
summary(features.pca) # top 20 principal components make up over 99% of variance, top 7 over 80%, and first two almost 50%
loadings.20 <- features.pca$loadings[,1:20]
loadings.7 <- features.pca$loadings[,1:7]
loadings.2 <- features.pca$loadings[,1:2]
prin.coms <- data.frame(as.matrix(features) %*% as.matrix(features.pca$loadings))

cv.mod.pca <- cv.glmnet(x = as.matrix(prin.coms), y = jazz, family = "binomial", type.measure = "class")
lambda.pca <- cv.mod.pca$lambda.min

mod.pca <- glmnet(prin.coms, jazz, family = "binomial", lambda = lambda.pca)
mod.probs.pca <- predict(mod.pca, newx = as.matrix(prin.coms), type = "response")
data$mod.probs.pca <- mod.probs.pca[,1]
jazz.class <- ifelse(data$jazz == 1, "jazz", "not jazz")
logistic.probs.pca <- data$mod.probs.pca
mod.cp.pca <- cutpointr(data.frame(jazz.class, logistic.probs.pca), x=logistic.probs.pca, class = jazz.class, method = maximize_metric, metric = accuracy)
summary(mod.cp.pca) # accuracy = 77.39%

plot(x = prin.coms$Comp.1, y = prin.coms$Comp.2, col = factor(data$genre), main = "Spotify Music by its first two principal components", xlab = "Pincipal Component 1", ylab = "Principal Componenet 2")
legend("bottomleft", legend=unique(data$genre),
       col=factor(unique(data$genre)), pch=1, cex=0.8,
       title="Genres", text.font=4)

logit <- mod.probs.pca/(1-mod.probs.pca)
ggpairs(cbind(prin.coms, logit))
plot(glm(jazz~., data = data.frame(prin.coms, jazz), family = "binomial")
, which = 4, id.n = 5)
car::vif(glm(jazz~., data = data.frame(prin.coms, jazz), family = "binomial")
)
```

```{r}
# first KNN

accuracy <- c()
for(i in 1:100){
  predicted <- knn(train = train.features, test = test.features, cl = train.jazz, k = i)
  ConMat <- table(test.jazz, predicted)
  TN <- ConMat[1,1]
  FP <- ConMat[1,2]
  FN <- ConMat[2,1]
  TP <- ConMat[2,2]
  accuracy[i] <- (TP + TN)/sum(ConMat)
}
plot(accuracy)
which.max(accuracy) # optimal K = 98
max(accuracy) #classification accuracy of 75.31%
```

```{r}
# second KNN (with PCA)

train.features.norm <- scale(train.features)
train.corr.mat <- cor(train.features.norm)
train.features.pca <- princomp(train.corr.mat)
summary(train.features.pca) # top 20 principal components make up over 99% of variance and first two almost 50%
train.prin.coms <- data.frame(as.matrix(train.features) %*% as.matrix(train.features.pca$loadings))

test.features.norm <- scale(test.features)
test.corr.mat <- cor(test.features.norm)
test.features.pca <- princomp(test.corr.mat)
summary(test.features.pca) 
test.prin.coms <- data.frame(as.matrix(test.features) %*% as.matrix(test.features.pca$loadings))

# all principal components
accuracy <- c()
for(i in 1:100){
  predicted <- knn(train = train.prin.coms, test = test.prin.coms, cl = train.jazz, k = i)
  ConMat <- table(test.jazz, predicted)
  TN <- ConMat[1,1]
  FP <- ConMat[1,2]
  FN <- ConMat[2,1]
  TP <- ConMat[2,2]
  accuracy[i] <- (TP + TN)/sum(ConMat)
}
plot(accuracy)
which.max(accuracy) # optimal K = 73
max(accuracy) # classification accuracy of 67.36%
```

```{r}
# testing for acoustic coherence 

rm(accuracy)
early <- data[data$year<=median(data$year),] # 402 observations
late <- data[data$year>median(data$year),] # 394 observations
early.features <- early[,c(5,8:33)]
early.jazz <- early$jazz
late.features <- late[,c(5,8:33)]
late.jazz <- late$jazz

# logistic regression with all variables (early)

cv.mod.early <- cv.glmnet(x = as.matrix(early.features), y = early.jazz, family = "binomial", type.measure = "class")
lambda <- cv.mod.early$lambda.min

mod.early <- glmnet(early.features, early.jazz, family = "binomial", lambda = lambda)
mod.early.probs <- predict(mod.early, newx = as.matrix(early.features), type = "response")
early$mod.early.probs <- mod.early.probs[,1]
early.jazz.class <- ifelse(early.jazz == 1, "jazz", "not jazz")
logistic.probs <- early$mod.early.probs
mod.early.cp <- cutpointr(data.frame(early.jazz.class, logistic.probs), x=logistic.probs, class = early.jazz.class, method = maximize_metric, metric = accuracy)
summary(mod.early.cp) # accuracy = 79.10%

7# logistic regression with all variables (late)

cv.mod.late <- cv.glmnet(x = as.matrix(late.features), y = late.jazz, family = "binomial", type.measure = "class")
lambda <- cv.mod.late$lambda.min

mod.late <- glmnet(late.features, late.jazz, family = "binomial", lambda = lambda)
mod.late.probs <- predict(mod.late, newx = as.matrix(late.features), type = "response")
late$mod.late.probs <- mod.late.probs[,1]
late.jazz.class <- ifelse(late.jazz == 1, "jazz", "not jazz")
logistic.probs <- late$mod.late.probs
mod.late.cp <- cutpointr(data.frame(late.jazz.class, logistic.probs), x=logistic.probs, class = late.jazz.class, method = maximize_metric, metric = accuracy)
summary(mod.late.cp) # accuracy = 80.20%

# logistic regression with principal components (early)

early.features.norm <- scale(early.features)
early.corr.mat <- cor(early.features.norm)
early.features.pca <- princomp(early.corr.mat)
summary(early.features.pca) 
early.prin.coms <- data.frame(as.matrix(early.features) %*% as.matrix(early.features.pca$loadings))

early.cv.mod.pca <- cv.glmnet(x = as.matrix(early.prin.coms), y = early.jazz, family = "binomial", type.measure = "class")
early.lambda.pca <- early.cv.mod.pca$lambda.min

early.mod.pca <- glmnet(early.prin.coms, early.jazz, family = "binomial", lambda = early.lambda.pca)
early.mod.probs.pca <- predict(early.mod.pca, newx = as.matrix(early.prin.coms), type = "response")
early$early.mod.probs.pca <- early.mod.probs.pca[,1]
early.jazz.class <- ifelse(early.jazz == 1, "jazz", "not jazz")
early.logistic.probs.pca <- early$early.mod.probs.pca
early.mod.cp.pca <- cutpointr(data.frame(early.jazz.class, early.logistic.probs.pca), x=early.logistic.probs.pca, class = early.jazz.class, method = maximize_metric, metric = accuracy)
summary(early.mod.cp.pca) # accuracy = 78.11%

# logistic regression with principal components (late)

late.features.norm <- scale(late.features)
late.corr.mat <- cor(late.features.norm)
late.features.pca <- princomp(late.corr.mat)
summary(late.features.pca) 
late.prin.coms <- data.frame(as.matrix(late.features) %*% as.matrix(late.features.pca$loadings))

late.cv.mod.pca <- cv.glmnet(x = as.matrix(late.prin.coms), y = late.jazz, family = "binomial", type.measure = "class")
late.lambda.pca <- late.cv.mod.pca$lambda.min

late.mod.pca <- glmnet(late.prin.coms, late.jazz, family = "binomial", lambda = late.lambda.pca)
late.mod.probs.pca <- predict(late.mod.pca, newx = as.matrix(late.prin.coms), type = "response")
late$late.mod.probs.pca <- late.mod.probs.pca[,1]
late.jazz.class <- ifelse(late.jazz == 1, "jazz", "not jazz")
late.logistic.probs.pca <- late$late.mod.probs.pca
late.mod.cp.pca <- cutpointr(data.frame(late.jazz.class, late.logistic.probs.pca), x=late.logistic.probs.pca, class = late.jazz.class, method = maximize_metric, metric = accuracy)
summary(late.mod.cp.pca) #79.19

# test for acoustic coherence (feature set)

accoustic.coherence.probs <- predict(early.mod.pca, newx = as.matrix(late.features), type = "response")
accoustic.coherence.cp <- cutpointr(data.frame(late.jazz.class, accoustic.coherence.probs), x=accoustic.coherence.probs, class = late.jazz.class, method = maximize_metric, metric = accuracy)
summary(accoustic.coherence.cp) # accuracy = 54.57%

# test for acoustic coherence (PCA)

accoustic.coherence.probs.pca <- predict(early.mod.pca, newx = as.matrix(late.prin.coms), type = "response")
accoustic.coherence.cp.pca <- cutpointr(data.frame(late.jazz.class, accoustic.coherence.probs.pca), x=accoustic.coherence.probs.pca, class = late.jazz.class, method = maximize_metric, metric = accuracy)
summary(accoustic.coherence.cp.pca) # accuracy = 51.02%
```

